{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,GlobalAveragePooling1D,LSTM,Flatten,Dropout,Dense\n",
    "from keras.preprocessing.text import one_hot\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('C:/deep learning/rnn/datasets/spam.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message\n",
       "0  Go until jurong point, crazy.. Available only ...\n",
       "1                      Ok lar... Joking wif u oni...\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3  U dun say so early hor... U c already then say...\n",
       "4  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.drop('Category',axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df['Category']= le.fit_transform(df['Category']) \n",
    "labels=df['Category']\n",
    "labels.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "messeges=X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove all punctuation and stopwords for pure data\n",
    "d=messeges['Message'][0]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lucifer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messeges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is a text preprocessing\n",
    "corpus=[]\n",
    "ps=PorterStemmer()\n",
    "for i in range(0,len(messeges)):\n",
    "    review=re.sub('[^a-zA-Z]',' ',messeges['Message'][i])\n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    review=[ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review=' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "vocab=5000\n",
    "encoded_docs=[one_hot(words,vocab) for words in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad sequence because differn sentence differnt lenght and embedding layer wants the sentence in same lenghth as output\n",
    "paded_docs=pad_sequences(encoded_docs,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(paded_docs)\n",
    "y=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 40)            200000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               56400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 256,501\n",
      "Trainable params: 256,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_vector=40\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab,embedding_vector,input_length=30))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data for model\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.2,random_state=40)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucifer\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/10\n",
      "4457/4457 [==============================] - 4s 834us/step - loss: 0.3669 - accuracy: 0.8692 - val_loss: 0.1928 - val_accuracy: 0.9274\n",
      "Epoch 2/10\n",
      "4457/4457 [==============================] - 3s 613us/step - loss: 0.1183 - accuracy: 0.9717 - val_loss: 0.0845 - val_accuracy: 0.9776\n",
      "Epoch 3/10\n",
      "4457/4457 [==============================] - 3s 639us/step - loss: 0.0425 - accuracy: 0.9886 - val_loss: 0.0637 - val_accuracy: 0.9821\n",
      "Epoch 4/10\n",
      "4457/4457 [==============================] - 2s 547us/step - loss: 0.0232 - accuracy: 0.9939 - val_loss: 0.0675 - val_accuracy: 0.9848\n",
      "Epoch 5/10\n",
      "4457/4457 [==============================] - 2s 543us/step - loss: 0.0162 - accuracy: 0.9964 - val_loss: 0.0663 - val_accuracy: 0.9803\n",
      "Epoch 6/10\n",
      "4457/4457 [==============================] - 3s 576us/step - loss: 0.0100 - accuracy: 0.9978 - val_loss: 0.0867 - val_accuracy: 0.9812\n",
      "Epoch 7/10\n",
      "4457/4457 [==============================] - 3s 595us/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 0.0938 - val_accuracy: 0.9731\n",
      "Epoch 8/10\n",
      "4457/4457 [==============================] - 3s 568us/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.0913 - val_accuracy: 0.9812\n",
      "Epoch 9/10\n",
      "4457/4457 [==============================] - 3s 606us/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0908 - val_accuracy: 0.9803\n",
      "Epoch 10/10\n",
      "4457/4457 [==============================] - 3s 609us/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0999 - val_accuracy: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2431810a908>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,verbose=1,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pre=model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[961,  10],\n",
       "       [ 14, 130]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97847533632287"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, Â£1.50 to rcv\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Message'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can you call later\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  3157 3984]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00987868]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the model accuracy with real data\n",
    "sent=input()\n",
    "input_msg=sent\n",
    "corpus=[]\n",
    "ps=PorterStemmer()\n",
    "for i in range(0,1):\n",
    "    review=re.sub('[^a-zA-Z]',' ',input_msg)\n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    review=[ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review=' '.join(review)\n",
    "    corpus.append(review)\n",
    "vocab=5000\n",
    "encoded_docs=[one_hot(words,vocab) for words in corpus]\n",
    "paded_docs=pad_sequences(encoded_docs,30)\n",
    "msg=np.array(paded_docs)\n",
    "print(msg)\n",
    "model.predict(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucifer\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/10\n",
      "4457/4457 [==============================] - 3s 746us/step - loss: 0.3778 - accuracy: 0.8629 - val_loss: 0.1836 - val_accuracy: 0.9480\n",
      "Epoch 2/10\n",
      "4457/4457 [==============================] - 3s 604us/step - loss: 0.1326 - accuracy: 0.9697 - val_loss: 0.0922 - val_accuracy: 0.9749\n",
      "Epoch 3/10\n",
      "4457/4457 [==============================] - 3s 598us/step - loss: 0.0452 - accuracy: 0.9888 - val_loss: 0.0745 - val_accuracy: 0.9785\n",
      "Epoch 4/10\n",
      "4457/4457 [==============================] - 3s 633us/step - loss: 0.0269 - accuracy: 0.9935 - val_loss: 0.0752 - val_accuracy: 0.9812\n",
      "Epoch 5/10\n",
      "4457/4457 [==============================] - 3s 592us/step - loss: 0.0173 - accuracy: 0.9964 - val_loss: 0.0806 - val_accuracy: 0.9776\n",
      "Epoch 6/10\n",
      "4457/4457 [==============================] - 3s 570us/step - loss: 0.0159 - accuracy: 0.9964 - val_loss: 0.0845 - val_accuracy: 0.9767\n",
      "Epoch 7/10\n",
      "4457/4457 [==============================] - 3s 570us/step - loss: 0.0109 - accuracy: 0.9973 - val_loss: 0.0934 - val_accuracy: 0.9749\n",
      "Epoch 8/10\n",
      "4457/4457 [==============================] - 3s 585us/step - loss: 0.0096 - accuracy: 0.9978 - val_loss: 0.1061 - val_accuracy: 0.9749\n",
      "Epoch 9/10\n",
      "4457/4457 [==============================] - 3s 592us/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.1202 - val_accuracy: 0.9740\n",
      "Epoch 10/10\n",
      "4457/4457 [==============================] - 3s 578us/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.0952 - val_accuracy: 0.9749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x16530e5ac88>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding dropout in modal to improve the accuracy\n",
    "embedding_vector=40\n",
    "model1=Sequential()\n",
    "model1.add(Embedding(vocab,embedding_vector,input_length=30))\n",
    "model1.add(LSTM(100))\n",
    "model1.add(Dropout(0.3))\n",
    "model1.add(Dense(1,activation='sigmoid'))\n",
    "model1.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model1.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,verbose=1,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[967,   4],\n",
       "       [ 24, 120]], dtype=int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pre=model1.predict_classes(X_test)\n",
    "confusion_matrix(y_test,y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9748878923766816"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
